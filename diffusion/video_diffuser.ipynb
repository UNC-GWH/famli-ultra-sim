{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import nrrd\n",
    "import SimpleITK as sitk\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "from diffusers import DDPMScheduler, UNet2DModel\n",
    "from PIL import Image\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "class DiffusionModel(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-5, num_train_timesteps=1000):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = UNet2DModel(\n",
    "            in_channels=1,  # the number of input channels, 3 for RGB images\n",
    "            out_channels=1,  # the number of output channels\n",
    "            layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "            block_out_channels=(256, 256, 512, 512, 1024, 1024),  # the number of output channes for each UNet block\n",
    "            down_block_types=( \n",
    "                \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "                \"DownBlock2D\", \n",
    "                \"DownBlock2D\", \n",
    "                \"DownBlock2D\", \n",
    "                \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "                \"DownBlock2D\",\n",
    "            ), \n",
    "            up_block_types=(\n",
    "                \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "                \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "                \"UpBlock2D\", \n",
    "                \"UpBlock2D\", \n",
    "                \"UpBlock2D\", \n",
    "                \"UpBlock2D\"  \n",
    "            ),\n",
    "        )\n",
    "        self.scheduler = DDPMScheduler(num_train_timesteps=num_train_timesteps, beta_schedule=\"linear\")\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, timesteps):\n",
    "        return self.net(x, timesteps).sample\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x= batch  # Ignore labels if they exist\n",
    "        timesteps = torch.randint(0, self.scheduler.config.num_train_timesteps, (x.size(0),), device=self.device).long()\n",
    "        noise = torch.randn_like(x).to(self.device)\n",
    "        noisy_images = self.scheduler.add_noise(x, noise, timesteps)\n",
    "\n",
    "        pred = self(noisy_images, timesteps)  # Model forward pass\n",
    "        loss = self.loss_fn(pred, noise)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch\n",
    "        timesteps = torch.randint(0, self.scheduler.config.num_train_timesteps, (x.size(0),), device=self.device)\n",
    "        outputs = self(x, timesteps)\n",
    "        loss = self.loss_fn(outputs, x)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.net.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer\n",
    "\n",
    "checkpoint_path = \"/mnt/raid/home/ajarry/data/outputs_lightning/final53epoch/model.pth\"\n",
    "model = DiffusionModel()\n",
    "state_dict = torch.load(checkpoint_path)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scheduler (make sure it matches the one used in training)\n",
    "scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule=\"linear\")\n",
    "\n",
    "# Set up sampling parameters\n",
    "image_size = (1, 1, 256, 256)  # Adjust shape (batch, channels, height, width)\n",
    "num_inference_steps =200  # Can be reduced for faster generation\n",
    "scheduler.set_timesteps(num_inference_steps)\n",
    "# Start with pure noise\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "noisy_image = torch.randn(image_size).to(device)\n",
    "\n",
    "# Sample timesteps\n",
    "timesteps = scheduler.timesteps.to(device)\n",
    "\n",
    "# Reverse process (denoising)\n",
    "with torch.no_grad():\n",
    "    for i, t in tqdm(enumerate(timesteps)):\n",
    "        # Predict noise\n",
    "        noise_pred = model(noisy_image, t.unsqueeze(0))\n",
    "        \n",
    "        # Remove noise using scheduler\n",
    "        noisy_image = scheduler.step(noise_pred, t, noisy_image).prev_sample\n",
    "\n",
    "# Convert to image format\n",
    "\n",
    "generated_image = noisy_image.cpu().squeeze(0).permute(1,2,0)\n",
    "\n",
    "print(generated_image.shape)\n",
    "\n",
    "plt.imshow(generated_image, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sitk.GetArrayFromImage(sitk.ReadImage('/mnt/raid/home/ajarry/data/cephalic_sweeps/frame_0001/C3_us.nrrd'))\n",
    "print(data.shape)\n",
    "fig = px.imshow(data,animation_frame=0, binary_string=True)\n",
    "fig.show()\n",
    "totensor = transforms.ToTensor()\n",
    "targets=[]\n",
    "for frame in data:\n",
    "    targets.append(totensor(np.uint8(frame)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guidance_loss(image, target):\n",
    "    return torch.abs(image - target).mean()\n",
    "\n",
    "# The guidance scale determines the strength of the effect\n",
    "guidance_loss_scale = 175 # Explore changing this to 5, or 100\n",
    "\n",
    "noise = torch.randn(1, 1, 256, 256).to(device)\n",
    "stack = []\n",
    "for target in targets:\n",
    "    x = noise\n",
    "    for i, t in tqdm(enumerate(scheduler.timesteps)):\n",
    "\n",
    "        # Prepare the model input\n",
    "        # model_input = scheduler.scale_model_input(x, t)\n",
    "\n",
    "        # predict the noise residual\n",
    "        with torch.no_grad():\n",
    "            noise_pred = model(x, t)\n",
    "\n",
    "        # Set x.requires_grad to True\n",
    "        x = x.detach().requires_grad_()\n",
    "\n",
    "        # Get the predicted x0\n",
    "        x0 = scheduler.step(noise_pred, t, x).pred_original_sample\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = guidance_loss(x0, target) * guidance_loss_scale\n",
    "        # if i % 10 == 0:\n",
    "        #     print(i, \"loss:\", loss.item())\n",
    "\n",
    "        # Get gradient\n",
    "        cond_grad = -torch.autograd.grad(loss, x)[0]\n",
    "\n",
    "        # Modify x based on this gradient\n",
    "        x = x.detach() + cond_grad\n",
    "\n",
    "        # Now step with scheduler\n",
    "        x = scheduler.step(noise_pred, t, x).prev_sample\n",
    "    stack.append(x.squeeze(0).cpu().permute(2,1,0))\n",
    "\n",
    "# print(x.shape)\n",
    "# img = x.squeeze(0).cpu().permute(1,2,0)\n",
    "\n",
    "# plt.imshow(img, cmap=\"gray\")\n",
    "# plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = np.stack(stack,axis=2).squeeze()\n",
    "print(volume.shape)\n",
    "out = '/mnt/raid/home/ajarry/data/image_capture_output/gpu4diffused.nrrd'\n",
    "nrrd.write(out,volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sitk.GetArrayFromImage(sitk.ReadImage('/mnt/raid/home/ajarry/data/cephalic_sweeps/frame_0001/C1_label.nrrd'))\n",
    "print(data.shape)\n",
    "fig = px.imshow(data,animation_frame=0, binary_string=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "nrrd_paths = [\n",
    "    path for path in glob.glob(\"/mnt/raid/home/ajarry/data/cephalic_sweeps/frame_*/*\")\n",
    "    if path.endswith(\".nrrd\") and \"us\" in os.path.basename(path).lower()\n",
    "]\n",
    "\n",
    "print(nrrd_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "difmod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
