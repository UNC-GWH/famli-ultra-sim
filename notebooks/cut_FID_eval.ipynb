{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plotting multiple values\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import nrrd\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "# sys.path.append(\"/mnt/raid/C1_ML_Analysis/source/autoencoder/src\")\n",
    "sys.path.append(\"/mnt/raid/C1_ML_Analysis/source/famli-ultra-sim/dl/\")\n",
    "sys.path.append(\"/mnt/raid/C1_ML_Analysis/source/famli-ultra-sim/dl/nets\")\n",
    "\n",
    "from nets import diffusion, spade, lotus, cut, layers, cut_G\n",
    "from loaders import ultrasound_dataset as usd\n",
    "import monai\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toint(x):\n",
    "    return (x*255).clamp(0, 255).to(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fid_all_types(dl, model, types=[\"Voluson\", \"Butterfly\", \"Clarius\"]):\n",
    "\n",
    "    values_real = [ ]\n",
    "    values_real_type = [ ]\n",
    "    values_fake = [ ]\n",
    "    values_fake_type = [ ]\n",
    "\n",
    "    metric = FrechetInceptionDistance(feature=64).cuda()\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        all_data = []\n",
    "        all_target = []\n",
    "\n",
    "        for x, y in dl:\n",
    "            all_data.append(x)\n",
    "            all_target.append(y)\n",
    "\n",
    "        all_data = torch.cat(all_data)\n",
    "        all_target = torch.cat(all_target)\n",
    "\n",
    "        idx = torch.arange(0, model.hparams.num_samples_test)*3\n",
    "\n",
    "        source0 = all_data[idx]\n",
    "        source0_target = all_target[idx]\n",
    "\n",
    "        source1 = all_data[idx+1]\n",
    "        source1_target = all_target[idx+1]\n",
    "\n",
    "        source2 = all_data[idx+2]\n",
    "        source2_target = all_target[idx+2]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            source0_fake = model(source0.cuda())\n",
    "            source1_fake = model(source1.cuda())\n",
    "            source2_fake = model(source2.cuda())\n",
    "\n",
    "        #       ___           ___           ___           ___ \n",
    "        #      /\\  \\         /\\  \\         /\\  \\         /\\__\\\n",
    "        #     /::\\  \\       /::\\  \\       /::\\  \\       /:/  /\n",
    "        #    /:/\\:\\  \\     /:/\\:\\  \\     /:/\\:\\  \\     /:/  / \n",
    "        #   /::\\~\\:\\  \\   /::\\~\\:\\  \\   /::\\~\\:\\  \\   /:/  /  \n",
    "        #  /:/\\:\\ \\:\\__\\ /:/\\:\\ \\:\\__\\ /:/\\:\\ \\:\\__\\ /:/__/   \n",
    "        #  \\/_|::\\/:/  / \\:\\~\\:\\ \\/__/ \\/__\\:\\/:/  / \\:\\  \\   \n",
    "        #     |:|::/  /   \\:\\ \\:\\__\\        \\::/  /   \\:\\  \\  \n",
    "        #     |:|\\/__/     \\:\\ \\/__/        /:/  /     \\:\\  \\ \n",
    "        #     |:|  |        \\:\\__\\         /:/  /       \\:\\__\\\n",
    "        #      \\|__|         \\/__/         \\/__/         \\/__/\n",
    "\n",
    "        # Voluson\n",
    "        \n",
    "        metric.update(toint(source0_target).repeat(1, 3, 1, 1).cuda(), real=True)\n",
    "        metric.update(toint(source0).repeat(1, 3, 1, 1).cuda(), real=False)\n",
    "        values_real.append(metric.compute())\n",
    "        values_real_type.append(types[0])\n",
    "\n",
    "        metric.reset()\n",
    "        # Butterfly\n",
    "        metric.update(toint(source1_target).repeat(1, 3, 1, 1).cuda(), real=True)\n",
    "        metric.update(toint(source1).repeat(1, 3, 1, 1).cuda(), real=False)\n",
    "\n",
    "        values_real.append(metric.compute())\n",
    "        values_real_type.append(types[1])\n",
    "\n",
    "        metric.reset()\n",
    "\n",
    "        # Clarius\n",
    "        metric.update(toint(source2_target).repeat(1, 3, 1, 1).cuda(), real=True)\n",
    "        metric.update(toint(source2).repeat(1, 3, 1, 1).cuda(), real=False)\n",
    "\n",
    "        values_real.append(metric.compute())\n",
    "        values_real_type.append(types[2])\n",
    "\n",
    "        metric.reset()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #       ___           ___           ___           ___     \n",
    "        #      /\\  \\         /\\  \\         /\\__\\         /\\  \\    \n",
    "        #     /::\\  \\       /::\\  \\       /:/  /        /::\\  \\   \n",
    "        #    /:/\\:\\  \\     /:/\\:\\  \\     /:/__/        /:/\\:\\  \\  \n",
    "        #   /::\\~\\:\\  \\   /::\\~\\:\\  \\   /::\\__\\____   /::\\~\\:\\  \\ \n",
    "        #  /:/\\:\\ \\:\\__\\ /:/\\:\\ \\:\\__\\ /:/\\:::::\\__\\ /:/\\:\\ \\:\\__\\\n",
    "        #  \\/__\\:\\ \\/__/ \\/__\\:\\/:/  / \\/_|:|~~|~    \\:\\~\\:\\ \\/__/\n",
    "        #       \\:\\__\\        \\::/  /     |:|  |      \\:\\ \\:\\__\\  \n",
    "        #        \\/__/        /:/  /      |:|  |       \\:\\ \\/__/  \n",
    "        #                    /:/  /       |:|  |        \\:\\__\\    \n",
    "        #                    \\/__/         \\|__|         \\/__/    \n",
    "\n",
    "\n",
    "\n",
    "        metric.reset()\n",
    "\n",
    "        # Voluson\n",
    "        metric.update(toint(source0_target).repeat(1, 3, 1, 1).cuda(), real=True)\n",
    "        metric.update(toint(source0_fake).repeat(1, 3, 1, 1).cuda(), real=False)\n",
    "\n",
    "        values_fake.append(metric.compute())\n",
    "        values_fake_type.append(types[0])\n",
    "\n",
    "        metric.reset()\n",
    "\n",
    "\n",
    "        # Butterfly\n",
    "\n",
    "        metric.update(toint(source1_target).repeat(1, 3, 1, 1).cuda(), real=True)\n",
    "        metric.update(toint(source1_fake).repeat(1, 3, 1, 1).cuda(), real=False)\n",
    "\n",
    "        values_fake.append(metric.compute())\n",
    "        values_fake_type.append(types[1])\n",
    "\n",
    "        metric.reset()\n",
    "\n",
    "        # Clarius\n",
    "        metric.update(toint(source2_target).repeat(1, 3, 1, 1).cuda(), real=True)\n",
    "        metric.update(toint(source2_fake).repeat(1, 3, 1, 1).cuda(), real=False)\n",
    "\n",
    "        values_fake.append(metric.compute())\n",
    "        values_fake_type.append(types[2])\n",
    "\n",
    "        metric.reset()\n",
    "\n",
    "    values_real = torch.stack(values_real)\n",
    "    values_fake = torch.stack(values_fake)\n",
    "    return values_real.cpu().numpy(), values_real_type, values_fake.cpu().numpy(), values_fake_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fréchet Inception Distance (FID)\n",
    "\n",
    "The **Fréchet Inception Distance (FID)** is a metric used to evaluate the quality of images generated by generative models such as GANs. It compares the **distribution of generated images** to the **distribution of real images** using features extracted from the **Inception v3** neural network.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- FID computes the **Fréchet distance** (also known as the Wasserstein-2 distance) between two multivariate Gaussians:\n",
    "  - One fitted to the **real image features**\n",
    "  - One fitted to the **generated image features**\n",
    "\n",
    "- The formula for FID:\n",
    "  \n",
    "  $$\n",
    "  \\text{FID} = \\|\\mu_r - \\mu_g\\|^2 + \\text{Tr}(\\Sigma_r + \\Sigma_g - 2(\\Sigma_r \\Sigma_g)^{1/2})\n",
    "  $$\n",
    "\n",
    "  where:\n",
    "  - $(\\mu_r, \\Sigma_r)$: mean and covariance of real images\n",
    "  - $(\\mu_g, \\Sigma_g)$: mean and covariance of generated images\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "- **Lower FID scores** indicate that the generated images are more similar to the real images.\n",
    "- FID is preferred over earlier metrics (like Inception Score) because it **captures both the quality and diversity** of generated images.\n",
    "\n",
    "## Applications\n",
    "\n",
    "- Commonly used in research to benchmark generative models like **GANs**.\n",
    "- Used in various image synthesis tasks, such as super-resolution, style transfer, and image generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cut.CutG.load_from_checkpoint(\"/mnt/raid/C1_ML_Analysis/train_output/Cut/allvslast/allvssonosite/v0.8/epoch=19-val_loss=6.33.ckpt\").eval().cuda()\n",
    "\n",
    "DATAMODULE = getattr(usd, model.hparams.data_module)\n",
    "data = DATAMODULE(**model.hparams)\n",
    "\n",
    "data.setup()\n",
    "dl = data.test_dataloader()\n",
    "\n",
    "values_real, values_real_type, values_fake, values_fake_type = compute_fid_all_types(dl, model, types=[\"Voluson\", \"Butterfly\", \"Clarius\"])\n",
    "\n",
    "df = pd.DataFrame(values_real, columns=[\"fid\"])\n",
    "df[\"is\"] = values_real_type\n",
    "df[\"type\"] = \"real\"\n",
    "\n",
    "df_fake = pd.DataFrame(values_fake, columns=[\"fid\"])\n",
    "df_fake[\"is\"] = values_fake_type\n",
    "df_fake[\"type\"] = \"fake\"\n",
    "\n",
    "df = pd.concat([df, df_fake])\n",
    "\n",
    "fig = px.scatter(df, x=\"is\", y=\"fid\", color=\"type\", title=\"All vs. Sonosite\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cut.CutG.load_from_checkpoint(\"/mnt/raid/C1_ML_Analysis/train_output/Cut/allvslast/allvsclarius/v0.3/epoch=14-val_loss=6.75.ckpt\").eval().cuda()\n",
    "DATAMODULE = getattr(usd, model.hparams.data_module)\n",
    "data = DATAMODULE(**model.hparams)\n",
    "data.setup()\n",
    "dl = data.test_dataloader()\n",
    "\n",
    "values_real, values_real_type, values_fake, values_fake_type = compute_fid_all_types(dl, model, types=[\"Voluson\", \"Butterfly\", \"Sonosite\"])\n",
    "\n",
    "df = pd.DataFrame(values_real, columns=[\"fid\"])\n",
    "df[\"is\"] = values_real_type\n",
    "df[\"type\"] = \"real\"\n",
    "\n",
    "df_fake = pd.DataFrame(values_fake, columns=[\"fid\"])\n",
    "df_fake[\"is\"] = values_fake_type\n",
    "df_fake[\"type\"] = \"fake\"\n",
    "\n",
    "df = pd.concat([df, df_fake])\n",
    "\n",
    "fig = px.scatter(df, x=\"is\", y=\"fid\", color=\"type\", title=\"ALL v.s. Clarius\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cut.CutG.load_from_checkpoint(\"/mnt/raid/C1_ML_Analysis/train_output/Cut/allvslast/allvsbutterfly/v0.1/epoch=22-val_loss=5.83.ckpt\").eval().cuda()\n",
    "DATAMODULE = getattr(usd, model.hparams.data_module)\n",
    "data = DATAMODULE(**model.hparams)\n",
    "data.setup()\n",
    "dl = data.test_dataloader()\n",
    "\n",
    "values_real, values_real_type, values_fake, values_fake_type = compute_fid_all_types(dl, model, types=[\"Voluson\", \"Sonosite\", \"Clarius\"])\n",
    "\n",
    "df = pd.DataFrame(values_real, columns=[\"fid\"])\n",
    "df[\"is\"] = values_real_type\n",
    "df[\"type\"] = \"real\"\n",
    "\n",
    "df_fake = pd.DataFrame(values_fake, columns=[\"fid\"])\n",
    "df_fake[\"is\"] = values_fake_type\n",
    "df_fake[\"type\"] = \"fake\"\n",
    "\n",
    "df = pd.concat([df, df_fake])\n",
    "\n",
    "fig = px.scatter(df, x=\"is\", y=\"fid\", color=\"type\", title=\"ALL v.s. Butterfly\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
