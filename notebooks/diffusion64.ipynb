{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641b449-2015-4da0-bf52-879abc9e37fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import nrrd\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import SimpleITK as sitk\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"/mnt/raid/C1_ML_Analysis/source/autoencoder/src\")\n",
    "\n",
    "from nets import diffusion\n",
    "from generative.inferers import DiffusionInferer\n",
    "from generative.networks.nets import DiffusionModelUNet\n",
    "from generative.networks.schedulers import DDPMScheduler, DDIMScheduler\n",
    "\n",
    "import monai\n",
    "from monai.transforms import (    \n",
    "    AsChannelFirst,\n",
    "    AddChannel,\n",
    "    Compose,    \n",
    "    Resize,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    CenterSpatialCrop,\n",
    "    ScaleIntensityRange,\n",
    "    RandAdjustContrast,\n",
    "    RandGaussianNoise,\n",
    "    RandGaussianSmooth\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee42bb8b-f156-435e-ad84-02404fff6be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = \"/mnt/raid/C1_ML_Analysis/train_output/diffusion/extract_frames_blind_sweeps_c1_30082022_wscores_1e-4_ddpmpl64_v1.0/epoch=6-val_loss=1.30.ckpt\"\n",
    "\n",
    "NN = getattr(diffusion, \"DDPMPL64\")\n",
    "model = NN.load_from_checkpoint(model_fn)\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e31e58-5f02-4cec-a685-bf3a56049042",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "inferer = DiffusionInferer(scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd37ec3-03b6-4ea9-8624-fc2685a9afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn((1, 1, 64, 64))\n",
    "noise = noise.cuda()\n",
    "scheduler.set_timesteps(num_inference_steps=1000)\n",
    "\n",
    "\n",
    "image, intermediates = inferer.sample(\n",
    "    input_noise=noise, diffusion_model=model.model, scheduler=scheduler, save_intermediates=True, intermediate_steps=100\n",
    ")\n",
    "\n",
    "chain = torch.cat(intermediates, dim=-1)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(chain[0, 0].cpu(), vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(image[0].cpu().permute(1,2,0), vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf5ffd3-3707-49cb-8196-354aec1ea4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autoencoder_fn = \"/mnt/raid/C1_ML_Analysis/train_output/diffusion/extract_frames_blind_sweeps_c1_30082022_wscores_1e-4_autoencoderlowkl_v1.0/last.ckpt\"\n",
    "\n",
    "NN = getattr(diffusion, \"AutoEncoderLowKL\")\n",
    "model_autoencoder = NN.load_from_checkpoint(model_autoencoder_fn).eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087e99c-8726-48c6-a05b-e952bf4975cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn((1, 1, 64, 64))\n",
    "noise = noise.cuda()\n",
    "scheduler.set_timesteps(num_inference_steps=1000)\n",
    "\n",
    "\n",
    "image, intermediates = inferer.sample(\n",
    "    input_noise=noise, diffusion_model=model.model, scheduler=scheduler, save_intermediates=True, intermediate_steps=100\n",
    ")\n",
    "\n",
    "# image = inferer.sample(\n",
    "#     input_noise=noise, diffusion_model=model.model, scheduler=scheduler, save_intermediates=False\n",
    "# )\n",
    "\n",
    "chain = torch.cat(intermediates, dim=-1)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(chain[0, 0].cpu(), vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(image[0].cpu().permute(1,2,0), vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "reconstruction, z_mu, z_sigma = model_autoencoder(image)\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(reconstruction[0].detach().cpu().permute(1,2,0), vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc38e88-28da-4980-a84c-c452a5e4f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_fn = \"/mnt/famli_netapp_shared/C1_ML_Analysis/src/blender/Pregnant_Fetus_Uterus_Blend_2-82/breech_3us_sweep_slices/1.nrrd\"\n",
    "sweep = sitk.ReadImage(sweep_fn)\n",
    "sweep_np = sitk.GetArrayFromImage(sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1282ecdb-cc83-4250-9792-2309770419bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_t = Resize([64, 64])(sweep_np)\n",
    "sweep_t = torch.tensor(sweep_t).cuda().to(torch.float32).unsqueeze(0)\n",
    "scheduler.set_timesteps(num_inference_steps=500)\n",
    "\n",
    "\n",
    "image, intermediates = inferer.sample(\n",
    "    input_noise=sweep_t, diffusion_model=model.model, scheduler=scheduler, save_intermediates=True, intermediate_steps=100\n",
    ")\n",
    "\n",
    "# image = inferer.sample(\n",
    "#     input_noise=noise, diffusion_model=model.model, scheduler=scheduler, save_intermediates=False\n",
    "# )\n",
    "\n",
    "chain = torch.cat(intermediates, dim=-1)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(chain[0, 0].cpu(), vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(image[0].cpu().permute(1,2,0), vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "reconstruction, z_mu, z_sigma = model_autoencoder(image)\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(reconstruction[0].detach().cpu().permute(1,2,0), vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84610b32-ca70-4188-927a-a50325ef6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sweep_t = Resize([64, 64])(sweep_np)\n",
    "sweep_t = torch.tensor(sweep_t).cuda().to(torch.float32).unsqueeze(0)\n",
    "\n",
    "guidance_scale = 100.0\n",
    "total_timesteps = 1000\n",
    "latent_space_depth = int(total_timesteps * 0.25)\n",
    "\n",
    "current_img = sweep_t\n",
    "scheduler_ddim = DDIMScheduler(num_train_timesteps=1000)\n",
    "inferer_ddim = DiffusionInferer(scheduler_ddim)\n",
    "\n",
    "scheduler_ddim.set_timesteps(num_inference_steps=total_timesteps)\n",
    "\n",
    "## Encoding\n",
    "\n",
    "scheduler_ddim.clip_sample = False\n",
    "# class_embedding = embed(torch.zeros(1).long().to(device)).unsqueeze(1)\n",
    "progress_bar = tqdm(range(latent_space_depth))\n",
    "for i in progress_bar:  # go through the noising process\n",
    "    t = i\n",
    "    with torch.no_grad():\n",
    "        model_output = model.model(current_img, timesteps=torch.Tensor((t,)).to(current_img.device))# , context=class_embedding)\n",
    "    current_img, _ = scheduler_ddim.reversed_step(model_output, t, current_img)\n",
    "    progress_bar.set_postfix({\"timestep input\": t})\n",
    "\n",
    "latent_img = current_img\n",
    "\n",
    "## Decoding\n",
    "# conditioning = torch.cat([torch.zeros(1).long(), torch.ones(1).long()], dim=0).to(device)\n",
    "# class_embedding = embed(conditioning).unsqueeze(1)\n",
    "\n",
    "progress_bar = tqdm(range(latent_space_depth))\n",
    "for i in progress_bar:  # go through the denoising process\n",
    "    t = latent_space_depth - i\n",
    "    current_img_double = torch.cat([current_img] * 2)\n",
    "    with torch.no_grad():\n",
    "        model_output = model.model(\n",
    "            current_img_double, timesteps=torch.Tensor([t, t]).to(current_img.device)#, context=class_embedding\n",
    "        )\n",
    "    noise_pred_uncond, noise_pred_text = model_output.chunk(2)\n",
    "    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "    current_img, _ = scheduler_ddim.step(noise_pred, t, current_img)\n",
    "    progress_bar.set_postfix({\"timestep input\": t})\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(sweep_np[0], vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(current_img.detach().cpu()[0][0], vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(latent_img.detach().cpu()[0][0], vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "reconstruction, z_mu, z_sigma = model_autoencoder(sweep_t)\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(reconstruction[0].detach().cpu().permute(1,2,0), vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4e0b9-7b08-408a-b130-b161ebaceaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vqvae_fn = \"/mnt/raid/C1_ML_Analysis/train_output/diffusion/extract_frames_blind_sweeps_c1_30082022_wscores_1e-4_vqvae_1.0/epoch=19-val_loss=0.03.ckpt\"\n",
    "\n",
    "NN = getattr(diffusion, \"VQVAEPL\")\n",
    "model_vqvae = NN.load_from_checkpoint(model_vqvae_fn).eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf55e1-2e48-4382-807d-a428b0fc31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_fn = \"/mnt/famli_netapp_shared/C1_ML_Analysis/src/blender/Pregnant_Fetus_Uterus_Blend_2-82/breech_3us_sweep_slices/100.nrrd\"\n",
    "sweep = sitk.ReadImage(sweep_fn)\n",
    "sweep_np = sitk.GetArrayFromImage(sweep).transpose([0,2,1])\n",
    "\n",
    "sweep_t = Resize([256, 256])(sweep_np)\n",
    "sweep_t = torch.tensor(sweep_t).cuda().to(torch.float32).unsqueeze(0)\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(sweep_np[0], vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "reconstruction, quantization_loss = model_vqvae(sweep_t)\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(reconstruction[0].detach().cpu().permute(1,2,0), vmin=0, vmax=1, cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
