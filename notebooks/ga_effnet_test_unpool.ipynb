{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import nrrd\n",
    "import vtk\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import pickle\n",
    "import monai \n",
    "import glob \n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sys.path.append('/mnt/famli_netapp_shared/C1_ML_Analysis/src/famli-ultra-sim/')\n",
    "sys.path.append('/mnt/famli_netapp_shared/C1_ML_Analysis/src/famli-ultra-sim/dl')\n",
    "import dl.loaders.ultrasound_dataset as ultrasound_dataset\n",
    "import dl.transforms.ultrasound_transforms as ultrasound_transforms\n",
    "import dl.loaders.mr_us_dataset as mr_us_dataset\n",
    "import dl.nets.us_simulation_jit as us_simulation_jit\n",
    "import dl.nets.us_simu as us_simu\n",
    "\n",
    "import importlib\n",
    "\n",
    "from dl.nets.layers import TimeDistributed\n",
    "\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models as tv_models\n",
    "from torchvision.ops import Conv2dNormActivation\n",
    "\n",
    "sys.path.append('/mnt/raid/C1_ML_Analysis/source/ShapeAXI/src/')\n",
    "\n",
    "from shapeaxi.saxi_layers import AttentionChunk, SelfAttention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tv_models.efficientnet_v2_s().features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0] = Conv2dNormActivation(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False, norm_layer=nn.BatchNorm2d, activation_layer=nn.SiLU)\n",
    "model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = model(torch.rand(1, 1, 256, 256))\n",
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionChunk(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, chunks=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.chunks = chunks\n",
    "        self.attn = SelfAttention(input_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Shape of x is [BS, T, C, H, W] or [BS, C, T, H, W]\n",
    "        # assert len(x.shape) == 5\n",
    "\n",
    "        x_out = []\n",
    "        x_shape = list(x.shape)\n",
    "        x_shape[1] = self.chunks\n",
    "        \n",
    "        for ch in torch.chunk(x, chunks=self.chunks, dim=1): # Iterate in the time dimension and create chunks\n",
    "            ch, _ = self.attn(ch, ch)\n",
    "            x_out.append(ch)\n",
    "        x_out = torch.stack(x_out, dim=1)\n",
    "        \n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = AttentionChunk(1280, 64, chunks=8)\n",
    "out = attn(torch.rand(1, 30, 8, 8, 1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
