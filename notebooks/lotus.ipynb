{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc53bd-56f5-49cc-b95a-105f52cb4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import functools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from math import pi\n",
    "import SimpleITK as sitk\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import vtk\n",
    "from vtk.util.numpy_support import vtk_to_numpy\n",
    "import pickle\n",
    "from monai.transforms import (RandSimulateLowResolution)\n",
    "import monai \n",
    "import pytorch_lightning as pl\n",
    "\n",
    "alpha_coeff_boundary_map = 0.1\n",
    "beta_coeff_scattering = 10  #100 approximates it closer\n",
    "TGC = 8\n",
    "CLAMP_VALS = True\n",
    "\n",
    "\n",
    "def gaussian_kernel(size: int, mean: float, std: float):\n",
    "    d1 = torch.distributions.Normal(mean, std)\n",
    "    d2 = torch.distributions.Normal(mean, std*3)\n",
    "    vals_x = d1.log_prob(torch.arange(-size, size+1, dtype=torch.float32)).exp()\n",
    "    vals_y = d2.log_prob(torch.arange(-size, size+1, dtype=torch.float32)).exp()\n",
    "\n",
    "    gauss_kernel = torch.einsum('i,j->ij', vals_x, vals_y)\n",
    "    \n",
    "    return gauss_kernel / torch.sum(gauss_kernel).reshape(1, 1)\n",
    "\n",
    "g_kernel = gaussian_kernel(3, 0., 0.5)\n",
    "g_kernel = torch.tensor(g_kernel[None, None, :, :])\n",
    "\n",
    "\n",
    "class UltrasoundRendering(pl.LightningModule):\n",
    "    def __init__(self, **kwargs): \n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        \n",
    "        # df = pd.read_csv(acoustic_params_fn)        \n",
    "        # accoustic_imped,attenuation,mu_0,mu_1,sigma_0\n",
    "        self.acoustic_impedance_dict = torch.nn.Parameter(torch.rand(self.hparams.num_labels))    # Z in MRayl\n",
    "        self.attenuation_dict =    torch.nn.Parameter(torch.rand(self.hparams.num_labels))   # alpha in dB cm^-1 at 1 MHz\n",
    "        self.mu_0_dict =           torch.nn.Parameter(torch.rand(self.hparams.num_labels)) # mu_0 - scattering_mu   mean brightness\n",
    "        self.mu_1_dict =           torch.nn.Parameter(torch.rand(self.hparams.num_labels)) # mu_1 - scattering density, Nr of scatterers/voxel\n",
    "        self.sigma_0_dict =        torch.nn.Parameter(torch.rand(self.hparams.num_labels)) # sigma_0 - scattering_sigma - brightness std\n",
    "        \n",
    "        grid, inverse_grid, mask = self.init_grids(self.hparams.grid_w, self.hparams.grid_h, self.hparams.center_x, self.hparams.center_y, self.hparams.r1, self.hparams.r2, self.hparams.theta)\n",
    "\n",
    "        self.register_buffer(\"grid\", grid)\n",
    "        self.register_buffer(\"inverse_grid\", inverse_grid)\n",
    "        self.register_buffer(\"mask_fan\", mask)\n",
    "\n",
    "        g_kernel = self.gaussian_kernel_asym(3, 0., 0.5)[None, None, :, :]\n",
    "        self.register_buffer(\"g_kernel\", g_kernel)\n",
    "\n",
    "        self.loss = nn.L1Loss()\n",
    "\n",
    "        \n",
    "    def init_params(self, df):\n",
    "        # df = pd.read_csv(acoustic_params_fn)\n",
    "        \n",
    "        # accoustic_imped,attenuation,mu_0,mu_1,sigma_0\n",
    "        self.acoustic_impedance_dict = torch.nn.Parameter(torch.tensor(df['acoustic_impedance_dict'], dtype=torch.float32))    # Z in MRayl\n",
    "        self.attenuation_dict =    torch.nn.Parameter(torch.tensor(df['attenuation_dict'], dtype=torch.float32))   # alpha in dB cm^-1 at 1 MHz\n",
    "        self.mu_0_dict =           torch.nn.Parameter(torch.tensor(df['mu_0_dict'], dtype=torch.float32)) # mu_0 - scattering_mu   mean brightness\n",
    "        self.mu_1_dict =           torch.nn.Parameter(torch.tensor(df['mu_1_dict'], dtype=torch.float32)) # mu_1 - scattering density, Nr of scatterers/voxel\n",
    "        self.sigma_0_dict =        torch.nn.Parameter(torch.tensor(df['sigma_0_dict'], dtype=torch.float32)) # sigma_0 - scattering_sigma - brightness std\n",
    "\n",
    "    def init_grids(self, w, h, center_x, center_y, r1, r2, theta):\n",
    "        grid = self.compute_grid(w, h, center_x, center_y, r1, r2, theta)\n",
    "        inverse_grid, mask = self.compute_grid_inverse(grid)\n",
    "        grid = self.normalize_grid(grid)\n",
    "        inverse_grid = self.normalize_grid(inverse_grid)\n",
    "\n",
    "        return  grid, inverse_grid, mask\n",
    "\n",
    "    def compute_grid(self, w, h, center_x, center_y, r1, r2, theta):\n",
    "\n",
    "        # Convert inputs to tensors\n",
    "        angles = torch.linspace(-theta, theta, w)  # Angles from -theta to theta\n",
    "        radii = torch.linspace(r1, r2, h)  # Linear space of radii\n",
    "\n",
    "        # Calculate sin and cos for all angles (broadcasting)\n",
    "        sin_angles = torch.sin(angles)\n",
    "        cos_angles = torch.cos(angles)\n",
    "\n",
    "        # Initialize the grid for intersection points\n",
    "        # Shape of grid: (h, w, 2) where 2 represents (x, y) coordinates\n",
    "        grid = torch.zeros(h, w, 2)\n",
    "\n",
    "        # Calculate intersections for each radius and angle\n",
    "        for i, radius in enumerate(radii):\n",
    "            x = (center_x + radius * sin_angles) # x coordinates for all angles at this radius\n",
    "            y = (center_y + radius * cos_angles) # y coordinates for all angles at this radius\n",
    "\n",
    "            grid[i] = torch.stack((x, y), dim=1)  # Update grid with coordinates\n",
    "\n",
    "        return grid\n",
    "        \n",
    "\n",
    "    def compute_grid_inverse(self, grid):\n",
    "\n",
    "        h, w, _ = grid.shape  # grid dimensions\n",
    "        inverse_grid = torch.zeros(h, w, 2)  # Initialize inverse grid\n",
    "        mask = torch.zeros(1, h, w)  # Initialize mask\n",
    "\n",
    "        # Iterate through each point in the grid\n",
    "        for j in range(h):\n",
    "            for i in range(w):\n",
    "                # Extract the polar coordinates (represented in the grid)\n",
    "                xi, yi = torch.round(grid[j, i]).to(torch.long)\n",
    "\n",
    "                # Place the Cartesian coordinates in the inverse grid\n",
    "                if 0 <= xi and xi < w and 0 <= yi and yi < h:\n",
    "                    inverse_grid[yi, xi] = torch.tensor([i, j])\n",
    "                    mask[0, yi, xi] = 1\n",
    "        return inverse_grid, self.morphology_close(mask.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "    def normalize_grid(self, grid):\n",
    "        h, w, _ = grid.shape  # grid dimensions\n",
    "        grid = grid / torch.tensor([h, w]) * 2.0 - 1.0\n",
    "        return grid\n",
    "\n",
    "    def dilate(self, x, kernel_size = 3):\n",
    "        kernel = torch.ones((1, 1, kernel_size, kernel_size), dtype=torch.float32)\n",
    "\n",
    "        # Apply convolution to simulate dilation\n",
    "        # We use padding=1 to ensure the output size is the same as the input size\n",
    "        output = F.conv2d(x, kernel, padding=1)\n",
    "\n",
    "        # Apply a threshold to get a binary output\n",
    "        dilated_image = (output > 0).float()\n",
    "\n",
    "        return dilated_image\n",
    "    \n",
    "    def erode(self, x, kernel_size = 3):\n",
    "        # Step 2: Erosion\n",
    "        # For erosion, invert the image and kernel, apply dilation, then invert the output\n",
    "        x = 1 - x\n",
    "        inverted_kernel = torch.ones((1, 1, kernel_size, kernel_size), dtype=torch.float32) # Same kernel as for dilation\n",
    "\n",
    "        # Apply convolution (dilation on inverted image) with padding to maintain size\n",
    "        eroded_output_inverted = F.conv2d(x, inverted_kernel, padding=1)\n",
    "\n",
    "        # Invert the result to get the final eroded (closing) result\n",
    "        eroded_image = 1 - (eroded_output_inverted > 0).float()\n",
    "\n",
    "        return eroded_image\n",
    "\n",
    "    def morphology_close(self, x, kernel_size=3):\n",
    "        return self.erode(self.dilate(x, kernel_size), kernel_size)\n",
    "\n",
    "    def add_speckle_noise(self, x, noise_variance=0.1):\n",
    "        \"\"\"\n",
    "        Adds speckle noise to an image.\n",
    "\n",
    "        Parameters:\n",
    "        - x: A PyTorch tensor representing the image, shape (C, H, W) or (B, C, H, W)\n",
    "        - noise_variance: Variance of the Gaussian noise\n",
    "\n",
    "        Returns:\n",
    "        - Noisy image: A PyTorch tensor of the same shape as `image` with speckle noise added\n",
    "        \"\"\"\n",
    "        # Ensure the noise is generated for each image in the batch\n",
    "        if x.dim() == 3: # For single image (C, H, W)\n",
    "            noise_shape = x.shape\n",
    "        elif x.dim() == 4: # For batch of images (B, C, H, W)\n",
    "            noise_shape = (x.size(0), 1, x.size(2), x.size(3))\n",
    "\n",
    "        # Generate noise from a normal distribution centered at 1 with specified variance\n",
    "        noise = 1 + torch.randn(noise_shape, device=x.device) * noise_variance\n",
    "\n",
    "        # Add noise to the image\n",
    "        return x * noise\n",
    "\n",
    "    \n",
    "    def gaussian_kernel_sym(self, size, sigma):\n",
    "        \"\"\"\n",
    "        Creates a 2D Gaussian kernel.\n",
    "\n",
    "        Args:\n",
    "        size (int): The size of the kernel.\n",
    "        sigma (float): The standard deviation of the Gaussian distribution.\n",
    "\n",
    "        Returns:\n",
    "        Tensor: A 2D Gaussian kernel.\n",
    "        \"\"\"\n",
    "        coords = torch.arange(size, dtype=torch.float32)\n",
    "        coords -= size // 2\n",
    "\n",
    "        g = coords**2\n",
    "        g = (-g / (2 * sigma**2)).exp()\n",
    "\n",
    "        g /= g.sum()\n",
    "        \n",
    "        gaussian = g.outer(g)\n",
    "        \n",
    "        return gaussian\n",
    "    \n",
    "    def gaussian_kernel_asym(self, size: int, mean: float, std: float):\n",
    "        d1 = torch.distributions.Normal(mean, std)\n",
    "        d2 = torch.distributions.Normal(mean, std*3)\n",
    "        vals_x = d1.log_prob(torch.arange(-size, size+1, dtype=torch.float32)).exp()\n",
    "        vals_y = d2.log_prob(torch.arange(-size, size+1, dtype=torch.float32)).exp()\n",
    "\n",
    "        gauss_kernel = torch.einsum('i,j->ij', vals_x, vals_y)\n",
    "\n",
    "        return gauss_kernel / torch.sum(gauss_kernel).reshape(1, 1)\n",
    "\n",
    "\n",
    "    def smooth(self, x, kernel_size=3, sigma=1, maxpool=True):\n",
    "        \"\"\"\n",
    "        Applies Gaussian blur to a batch of images.\n",
    "\n",
    "        Args:\n",
    "        images (Tensor): Input images with shape (N, C, H, W).\n",
    "        kernel_size (int): The size of the Gaussian kernel.\n",
    "        sigma (float): The standard deviation of the Gaussian distribution.\n",
    "\n",
    "        Returns:\n",
    "        Tensor: The smoothed images.\n",
    "        \"\"\"\n",
    "        # Create a Gaussian kernel\n",
    "        kernel = self.gaussian_kernel_sym(kernel_size, sigma).to(x.device)\n",
    "        \n",
    "        kernel = kernel.expand(x.size(1), 1, kernel_size, kernel_size)\n",
    "\n",
    "        # Apply the Gaussian kernel to each image in the batch\n",
    "        padding = kernel_size // 2\n",
    "        \n",
    "        if maxpool:\n",
    "            x = torch.nn.MaxPool2d(kernel_size, stride=1, padding=1)(x)\n",
    "            \n",
    "        return F.conv2d(x, kernel, padding=padding, groups=x.size(1))\n",
    "    \n",
    "    def rendering(self, shape, attenuation_medium_map, mu_0_map, mu_1_map, sigma_0_map, z_vals=None, refl_map=None, boundary_map=None):\n",
    "        \n",
    "        dists = torch.abs(z_vals[..., :-1, None] - z_vals[..., 1:, None])     # dists.shape=(W, H-1, 1)\n",
    "        dists = dists.squeeze(-1)                                             # dists.shape=(W, H-1)\n",
    "        dists = torch.cat([dists, dists[:, -1, None]], dim=-1)                # dists.shape=(W, H)\n",
    "\n",
    "        attenuation = torch.exp(-attenuation_medium_map * dists)\n",
    "        attenuation_total = torch.cumprod(attenuation, dim=3, dtype=torch.float32, out=None)\n",
    "\n",
    "        gain_coeffs = torch.linspace(1, self.hparams.tgc, attenuation_total.shape[3], device=self.device)\n",
    "        gain_coeffs = torch.tile(gain_coeffs, (attenuation_total.shape[2], 1))\n",
    "        attenuation_total = attenuation_total * gain_coeffs     # apply TGC\n",
    "\n",
    "        reflection_total = torch.cumprod(1. - refl_map * boundary_map, dim=3, dtype=torch.float32, out=None) \n",
    "        reflection_total = reflection_total.squeeze(-1) \n",
    "        reflection_total_plot = torch.log(reflection_total + torch.finfo(torch.float32).eps)\n",
    "\n",
    "        texture_noise = torch.randn(shape, dtype=torch.float32, device=self.device)\n",
    "        scattering_probability = torch.randn(shape, dtype=torch.float32, device=self.device)\n",
    "\n",
    "        # scattering_zero = torch.zeros(shape, dtype=torch.float32)\n",
    "\n",
    "        z = mu_1_map - scattering_probability\n",
    "        sigmoid_map = torch.sigmoid(self.hparams.beta_coeff_scattering * z)\n",
    "\n",
    "        # approximating  Eq. (4) to be differentiable:\n",
    "        # where(scattering_probability <= mu_1_map, \n",
    "        #                     texture_noise * sigma_0_map + mu_0_map, \n",
    "        #                     scattering_zero)\n",
    "        # scatterers_map =  (sigmoid_map) * (texture_noise * sigma_0_map + mu_0_map) + (1 -sigmoid_map) * scattering_zero   # Eq. (6)\n",
    "        scatterers_map =  (sigmoid_map) * (texture_noise * sigma_0_map + mu_0_map)\n",
    "\n",
    "        psf_scatter_conv = torch.nn.functional.conv2d(input=scatterers_map, weight=self.g_kernel, stride=1, padding=\"same\")\n",
    "        # psf_scatter_conv = psf_scatter_conv.squeeze()\n",
    "\n",
    "        b = attenuation_total * psf_scatter_conv    # Eq. (3)\n",
    "\n",
    "        border_convolution = torch.nn.functional.conv2d(input=boundary_map, weight=self.g_kernel, stride=1, padding=\"same\")\n",
    "        # border_convolution = border_convolution.squeeze()\n",
    "\n",
    "        r = attenuation_total * reflection_total * refl_map * border_convolution # Eq. (2)\n",
    "        \n",
    "        intensity_map = b + r   # Eq. (1)\n",
    "        # intensity_map = intensity_map.squeeze() \n",
    "        intensity_map = torch.clamp(intensity_map, 0, 1)\n",
    "\n",
    "        return intensity_map, attenuation_total, reflection_total_plot, scatterers_map, scattering_probability, border_convolution, texture_noise, b, r\n",
    "    \n",
    "    def render_rays(self, W, H):\n",
    "        N_rays = W \n",
    "        t_vals = torch.linspace(0., 1., H, device=self.device)\n",
    "        z_vals = t_vals.unsqueeze(0).expand(N_rays , -1) * 4 \n",
    "\n",
    "        return z_vals\n",
    "\n",
    "    def forward(self, x, grid=None, inverse_grid=None, mask_fan=None, return_seg=False):\n",
    "\n",
    "        if grid is None:\n",
    "\n",
    "            #init tissue maps\n",
    "            #generate maps from the dictionary and the input label map\n",
    "            repeats = [1,]*len(x.shape)\n",
    "            repeats[0] = x.shape[0]\n",
    "\n",
    "            grid = self.grid\n",
    "            inverse_grid = self.inverse_grid\n",
    "            mask_fan = self.mask_fan\n",
    "\n",
    "            grid = grid.repeat(repeats)\n",
    "            inverse_grid = inverse_grid.repeat(repeats)\n",
    "            mask_fan = mask_fan.repeat(repeats)\n",
    "\n",
    "        #UNWARP\n",
    "        x = F.grid_sample(x.float(), grid, mode='nearest', padding_mode='zeros', align_corners=True)\n",
    "\n",
    "        x = torch.rot90(x, k=1, dims=[2, 3])\n",
    "        x = x.to(torch.long)\n",
    "        \n",
    "        acoustic_imped_map = self.acoustic_impedance_dict[x]\n",
    "        attenuation_medium_map = self.attenuation_dict[x]\n",
    "        mu_0_map = self.mu_0_dict[x]\n",
    "        mu_1_map = self.mu_1_dict[x]\n",
    "        sigma_0_map = self.sigma_0_dict[x]\n",
    "\n",
    "        \n",
    "        #Comput the difference along dimension 2\n",
    "        diff_arr = torch.diff(acoustic_imped_map, dim=2)                \n",
    "        # The pad tuple is (padding_left,padding_right, padding_top,padding_bottom)\n",
    "        # The array is padded at the top\n",
    "        diff_arr = F.pad(diff_arr, (0,0,1,0))\n",
    "\n",
    "        #Compute the boundary map using the diff_array\n",
    "        boundary_map =  -torch.exp(-(diff_arr**2)/self.hparams.alpha_coeff_boundary_map) + 1\n",
    "        \n",
    "        #Roll/shift the elements along dimension 2 and set the last element to 0\n",
    "        shifted_arr = torch.roll(acoustic_imped_map, -1, dims=2)\n",
    "        shifted_arr[-1:] = 0\n",
    "\n",
    "        # This computes the sum/accumulation along the direction and set elements that are 0 to 1. Compute the division\n",
    "        sum_arr = acoustic_imped_map + shifted_arr\n",
    "        sum_arr[sum_arr == 0] = 1\n",
    "        div = diff_arr / sum_arr\n",
    "        # Compute the reflection from the elements\n",
    "        refl_map = div ** 2\n",
    "        refl_map = torch.sigmoid(refl_map)      # 1 / (1 + (-refl_map).exp())\n",
    "\n",
    "        z_vals = self.render_rays(x.shape[2], x.shape[3])\n",
    "\n",
    "        # if CLAMP_VALS:\n",
    "        #     attenuation_medium_map = torch.clamp(attenuation_medium_map, 0, 10)\n",
    "        #     acoustic_imped_map = torch.clamp(acoustic_imped_map, 0, 10)\n",
    "        #     sigma_0_map = torch.clamp(sigma_0_map, 0, 1)\n",
    "        #     mu_1_map = torch.clamp(mu_1_map, 0, 1)\n",
    "        #     mu_0_map = torch.clamp(mu_0_map, 0, 1)\n",
    "\n",
    "        ret_list = self.rendering(x.shape, attenuation_medium_map, mu_0_map, mu_1_map, sigma_0_map, z_vals=z_vals, refl_map=refl_map, boundary_map=boundary_map)\n",
    "\n",
    "        intensity_map  = ret_list[0]\n",
    "\n",
    "        x = torch.rot90(x, k=3, dims=[2, 3])\n",
    "        intensity_map = torch.rot90(intensity_map, k=3, dims=[2, 3])\n",
    "        \n",
    "        x = F.grid_sample(x.float(), inverse_grid, mode='nearest', padding_mode='zeros', align_corners=True).long()\n",
    "        intensity_map = F.grid_sample(intensity_map.float(), inverse_grid, mode='bilinear', padding_mode='zeros', align_corners=True)\n",
    "\n",
    "        # return intensity_map, x, attenuation_medium_map, mu_0_map, mu_1_map, sigma_0_map, acoustic_imped_map, boundary_map, shifted_arr\n",
    "        \n",
    "        intensity_map = intensity_map * mask_fan\n",
    "\n",
    "        #intensity_map_s = self.smooth(intensity_map)\n",
    "        #intensity_map[mask_fan==0] = intensity_map_s[mask_fan==0]\n",
    "\n",
    "        # return intensity_map, x, attenuation_medium_map, mu_0_map, mu_1_map, sigma_0_map, acoustic_imped_map, boundary_map, shifted_arr\n",
    "        if return_seg:\n",
    "            return intensity_map, x\n",
    "        return intensity_map\n",
    "    \n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):        \n",
    "        \n",
    "        optimizer = optim.AdamW(self.parameters(),\n",
    "                                lr=self.hparams.lr,\n",
    "                                weight_decay=self.hparams.weight_decay)\n",
    "        \n",
    "        return optimizer\n",
    "    \n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        seg = train_batch['seg']\n",
    "        img = train_batch['img']\n",
    "\n",
    "        fake_us = self(seg)[0]\n",
    "\n",
    "        repeats = [1,]*len(img.shape)\n",
    "        repeats[0] = img.shape[0]\n",
    "        mask_fan = self.mask_fan.repeat(repeats)\n",
    "        img = mask_fan*img\n",
    "\n",
    "        loss = self.loss(fake_us, img)\n",
    "\n",
    "        self.log(\"loss\", loss)\n",
    "\n",
    "        return loss\n",
    "        \n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):        \n",
    "        seg = val_batch['seg']\n",
    "        img = val_batch['img']\n",
    "\n",
    "        fake_us = self(seg)[0]\n",
    "\n",
    "        repeats = [1,]*len(img.shape)\n",
    "        repeats[0] = img.shape[0]\n",
    "        mask_fan = self.mask_fan.repeat(repeats)\n",
    "        img = mask_fan*img\n",
    "\n",
    "        val_loss = self.loss(fake_us, img)\n",
    "\n",
    "        self.log(\"val_loss\", val_loss, sync_dist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1204897-432b-4181-a814-0a9702c7ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"/mnt/raid/C1_ML_Analysis/source/blender/simulated_data_export/FAM-202-1960-2_mesh_sampling/AC/40.nrrd\"\n",
    "img = sitk.ReadImage(fn)\n",
    "img1_np = sitk.GetArrayFromImage(img)\n",
    "px.imshow(img1_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c1cc5-bde1-4d8f-a209-0f1c798477be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"/mnt/raid/C1_ML_Analysis/source/blender/simulated_data_export/FAM-202-1960-2_mesh_sampling/AC/98.nrrd\"\n",
    "img = sitk.ReadImage(fn)\n",
    "img2_np = sitk.GetArrayFromImage(img)\n",
    "px.imshow(img2_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bbeb3f-f3cd-4ac0-9461-97bc70aeb525",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_np = np.stack([img1_np, img2_np]).astype(np.int_)\n",
    "img_np.shape\n",
    "t = torch.tensor(img_np).to(torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b7174-b50f-4357-9752-57dd6bb2fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_params_df = pd.read_csv('/mnt/raid/C1_ML_Analysis/source/blender/simulated_data_export/acoustic_params_v2.csv')\n",
    "# acoustic_params_df.loc[0, 'mu_0_dict'] = 0.1\n",
    "# acoustic_params_df.loc[256, 'attenuation_dict'] = 2\n",
    "# us_render = UltrasoundRendering(num_labels=len(acoustic_params_df.index), grid_w=256, grid_h=256, center_x=128.0, center_y=-40.0, r1=20, r2=224, theta=np.pi/4.0, alpha_coeff_boundary_map=0.1, beta_coeff_scattering=1.0, tgc=8)\n",
    "us_render.init_params(acoustic_params_df)\n",
    "us_render.eval()\n",
    "fake_us = us_render(t)\n",
    "px.imshow(fake_us[0][0].detach().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb1a58-cd92-4701-9654-b3e1b24de3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_params_df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bfbb2f-0386-4e3e-b91b-2be666b4cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.normal(mean=torch.ones(3)*3.0, std=torch.ones(3)*1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5f8d5-37b1-4891-b35f-f4b2aab06fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
