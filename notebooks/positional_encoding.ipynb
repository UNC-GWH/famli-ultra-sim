{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44afb4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import nrrd\n",
    "import vtk\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import pickle\n",
    "import monai \n",
    "import glob \n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "sys.path.append('/mnt/raid/C1_ML_Analysis/source/famli-ultra-sim/')\n",
    "sys.path.append('/mnt/raid/C1_ML_Analysis/source/famli-ultra-sim/dl')\n",
    "import dl.loaders.ultrasound_dataset as ultrasound_dataset\n",
    "import dl.transforms.ultrasound_transforms as ultrasound_transforms\n",
    "import dl.nets.us_simulation_jit as us_simulation_jit\n",
    "import dl.nets.us_simu as us_simu\n",
    "\n",
    "import importlib\n",
    "\n",
    "from pytorch3d.ops import (knn_points, \n",
    "                           knn_gather)\n",
    "\n",
    "sys.path.append('/mnt/raid/C1_ML_Analysis/source/ShapeAXI/src/')\n",
    "from shapeaxi.saxi_layers import SelfAttention\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d1b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(seq_len: int, d_model: int, tag: int, device='cpu') -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Sinusoidal positional encoding with tag-based offset.\n",
    "\n",
    "    Args:\n",
    "        seq_len (int): Sequence length.\n",
    "        d_model (int): Embedding dimension.\n",
    "        tag (int): Unique tag for the sequence.\n",
    "        device (str): Device to store the tensor.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Positional encoding (seq_len, d_model).\n",
    "    \"\"\"\n",
    "    pe = torch.zeros(seq_len, d_model, device=device)\n",
    "    \n",
    "    # Offset positions by a tag-dependent amount to make each sequence encoding unique\n",
    "    position = torch.arange(tag * seq_len, (tag + 1) * seq_len, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32, device=device) * (-math.log(10000.0) / d_model))\n",
    "    \n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    \n",
    "    return pe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c190ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "penc = positional_encoding(seq_len=100, d_model=512, tag=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0560a7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154204c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
