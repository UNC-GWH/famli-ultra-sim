{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113e45f5-bc1e-4650-b328-2e443fbb883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import nrrd\n",
    "import vtk\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import pickle\n",
    "import monai \n",
    "import glob \n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sys.path.append('/mnt/raid/C1_ML_Analysis/source/famli-ultra-sim/')\n",
    "sys.path.append('/mnt/raid/C1_ML_Analysis/source/famli-ultra-sim/dl')\n",
    "import dl.transforms.ultrasound_transforms as ultrasound_transforms\n",
    "import dl.loaders.mr_us_dataset as mr_us_dataset\n",
    "import dl.nets.us_simulation_jit as us_simulation_jit\n",
    "import dl.nets.us_simu as us_simu\n",
    "\n",
    "import importlib\n",
    "\n",
    "from dl.nets.layers import TimeDistributed\n",
    "\n",
    "sys.path.append('/mnt/raid/C1_ML_Analysis/source/ShapeAXI/src')\n",
    "from shapeaxi import utils as saxi_utils\n",
    "from shapeaxi.saxi_transforms import EvalTransform\n",
    "\n",
    "from pytorch3d.ops import (sample_points_from_meshes,\n",
    "                           knn_points, \n",
    "                           knn_gather,\n",
    "                           sample_farthest_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3bc806",
   "metadata": {},
   "outputs": [],
   "source": [
    "mount_point = '/mnt/raid/C1_ML_Analysis'\n",
    "\n",
    "importlib.reload(us_simu)\n",
    "vs = us_simu.VolumeSamplingBlindSweep(mount_point=mount_point)\n",
    "vs = vs.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec6cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# diffusor = sitk.ReadImage('/mnt/famli_netapp_shared/C1_ML_Analysis/src/blender/simulated_data_export/studies_merged/FAM-025-0447-5.nrrd')\n",
    "# diffusor_np = sitk.GetArrayFromImage(diffusor)\n",
    "# diffusor_t = torch.tensor(diffusor_np.astype(int))\n",
    "\n",
    "# diffusor_spacing = torch.tensor(diffusor.GetSpacing()).flip(dims=[0])\n",
    "# diffusor_size = torch.tensor(diffusor.GetSize()).flip(dims=[0])\n",
    "\n",
    "# diffusor_origin = torch.tensor(diffusor.GetOrigin()).flip(dims=[0])\n",
    "# diffusor_end = diffusor_origin + diffusor_spacing * diffusor_size\n",
    "# print(diffusor_size)\n",
    "# print(diffusor_spacing)\n",
    "# print(diffusor_t.shape)\n",
    "# print(diffusor_origin)\n",
    "# print(diffusor_end)\n",
    "\n",
    "diffusor_np, diffusor_head = nrrd.read('/mnt/raid//C1_ML_Analysis/simulated_data_export/placenta/FAM-025-0664-4_label11_resampled.nrrd')\n",
    "diffusor_t = torch.tensor(diffusor_np.astype(int)).permute(2, 1, 0)\n",
    "\n",
    "print(diffusor_head)\n",
    "diffusor_size = torch.tensor(diffusor_head['sizes'])\n",
    "diffusor_spacing = torch.tensor(np.diag(diffusor_head['space directions']))\n",
    "\n",
    "diffusor_origin = torch.tensor(diffusor_head['space origin']).flip(dims=[0])\n",
    "diffusor_end = diffusor_origin + diffusor_spacing * diffusor_size\n",
    "print(diffusor_spacing)\n",
    "print(diffusor_t.shape)\n",
    "print(diffusor_origin)\n",
    "print(diffusor_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d81c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.imshow(diffusor_t.flip(dims=[1]).squeeze().cpu().numpy(), animation_frame=0, binary_string=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bae68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusor_batch_t = diffusor_t.permute([2, 1, 0]).cuda().float().unsqueeze(0).unsqueeze(0)\n",
    "diffusor_batch_t = diffusor_t.cuda().float().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "diffusor_origin_batch = diffusor_origin[None, :]\n",
    "diffusor_end_batch = diffusor_end[None, :]\n",
    "\n",
    "print(diffusor_batch_t.shape, diffusor_origin_batch.shape, diffusor_origin_batch.shape)\n",
    "# print(diffusor_origin_batch.shape)\n",
    "\n",
    "diffusor_in_fov_t = vs.diffusor_in_fov(diffusor_batch_t, diffusor_origin_batch.cuda(), diffusor_end_batch.cuda())\n",
    "\n",
    "print(diffusor_in_fov_t.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a858b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "fov_physical = vs.fov_physical()\n",
    "\n",
    "# repeats = [1,]*len(out_fovs.shape)\n",
    "# repeats[0] = out_fovs.shape[0]\n",
    "\n",
    "# fov_physical = fov_physical.repeat(repeats)\n",
    "\n",
    "V_fov = fov_physical.reshape(-1, 3).cuda()\n",
    "\n",
    "V_ = []\n",
    "VF_ = []\n",
    "\n",
    "for diff_in_fov in diffusor_in_fov_t:\n",
    "        \n",
    "        diff_in_fov = diff_in_fov.reshape(-1, 1)\n",
    "        \n",
    "        V_filtered = V_fov[diff_in_fov.squeeze() == 5]\n",
    "        F_filtered = diff_in_fov[diff_in_fov.squeeze() == 5]\n",
    "        V_.append(V_filtered)\n",
    "        VF_.append(F_filtered)\n",
    "\n",
    "V = pad_sequence(V_, batch_first=True, padding_value=0.0) \n",
    "VF = pad_sequence(VF_, batch_first=True, padding_value=0.0)\n",
    "\n",
    "print(V.shape, VF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_v = V\n",
    "SN = 0\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(x=x_v[SN,:,0].detach().cpu().numpy(), y=x_v[SN,:,1].detach().cpu().numpy(), z=x_v[SN,:,2].detach().cpu().numpy(), mode='markers', marker=dict(\n",
    "        size=2,\n",
    "        color=x_v[SN,:,2].detach().cpu().numpy(),                # set color to an array/list of desired values\n",
    "        colorscale='jet',   # choose a colorscale\n",
    "        # opacity=0.5\n",
    "    ))])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c334ea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.imshow(diffusor_in_fov_t[0].squeeze().flip(dims=[1]).cpu().numpy(), animation_frame=0, binary_string=True)\n",
    "# fig.show()\n",
    "# fig = px.imshow(diffusor_in_fov_t[1].squeeze().flip(dims=[1]).cpu().numpy(), animation_frame=0, binary_string=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf787f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf = saxi_utils.ReadSurf('/mnt/raid/C1_ML_Analysis/simulated_data_export/studies_fetus/FAM-025-0664-4_Fetus_Model.vtk')\n",
    "V_surf, F_surf = saxi_utils.PolyDataToTensors_v_f(surf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dcab3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.load('/mnt/raid/C1_ML_Analysis/simulated_data_export/dists_Fetus_Model.npy')\n",
    "idx = torch.tensor(idx, dtype=torch.int64, device=V_surf.device)\n",
    "\n",
    "P = knn_gather(V_surf.unsqueeze(0), idx).squeeze(-2).squeeze(0).contiguous()\n",
    "P = EvalTransform()(P)\n",
    "\n",
    "P = P.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(x=P[SN,:,2].detach().cpu().numpy(), y=P[SN,:,1].detach().cpu().numpy(), z=P[SN,:,0].detach().cpu().numpy(), mode='markers', marker=dict(\n",
    "        size=2,\n",
    "        color=P[SN,:,2].detach().cpu().numpy(),                # set color to an array/list of desired values\n",
    "        colorscale='jet',   # choose a colorscale\n",
    "        # opacity=0.5\n",
    "    ))])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a1b5378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotate_3d_batch(image_tensor):\n",
    "    \"\"\"\n",
    "    Randomly rotates a batch of 3D image tensors and returns the rotated images along with the rotation matrices.\n",
    "    \n",
    "    Args:\n",
    "        image_tensor (torch.Tensor): A tensor of shape (B, C, D, H, W).\n",
    "    \n",
    "    Returns:\n",
    "        rotated_images (torch.Tensor): Rotated 3D tensors of shape (B, C, D, H, W).\n",
    "        rotation_matrices (torch.Tensor): Rotation matrices of shape (B, 3, 3).\n",
    "    \"\"\"\n",
    "    assert len(image_tensor.shape) == 5, \"Input tensor must be 5D (B, C, D, H, W).\"\n",
    "\n",
    "    B, C, D, H, W = image_tensor.shape\n",
    "\n",
    "    # Generate random angles for each batch (B, 3)\n",
    "    angles = torch.rand(B, 3) * 2 * torch.pi  # Random angles between 0 and 2*pi\n",
    "\n",
    "    # Helper functions to create rotation matrices\n",
    "    def rotation_matrix_x(angle):\n",
    "        return torch.tensor([\n",
    "            [1, 0, 0],\n",
    "            [0, torch.cos(angle), -torch.sin(angle)],\n",
    "            [0, torch.sin(angle), torch.cos(angle)]\n",
    "        ], device=image_tensor.device)\n",
    "\n",
    "    def rotation_matrix_y(angle):\n",
    "        return torch.tensor([\n",
    "            [torch.cos(angle), 0, torch.sin(angle)],\n",
    "            [0, 1, 0],\n",
    "            [-torch.sin(angle), 0, torch.cos(angle)]\n",
    "        ], device=image_tensor.device)\n",
    "\n",
    "    def rotation_matrix_z(angle):\n",
    "        return torch.tensor([\n",
    "            [torch.cos(angle), -torch.sin(angle), 0],\n",
    "            [torch.sin(angle), torch.cos(angle), 0],\n",
    "            [0, 0, 1]\n",
    "        ], device=image_tensor.device)\n",
    "\n",
    "    # Generate rotation matrices for each sample in the batch\n",
    "    rotation_matrices = torch.stack([\n",
    "        rotation_matrix_z(angles[i, 2]) @ \n",
    "        rotation_matrix_y(angles[i, 1]) @ \n",
    "        rotation_matrix_x(angles[i, 0])\n",
    "        for i in range(B)\n",
    "    ])\n",
    "\n",
    "    # Convert 3x3 rotation matrices to 3x4 affine matrices\n",
    "    affine_matrices = torch.cat([rotation_matrices, torch.zeros(B, 3, 1, device=image_tensor.device)], dim=2)\n",
    "\n",
    "    # Generate affine grids for each batch\n",
    "    grids = F.affine_grid(\n",
    "        affine_matrices,\n",
    "        size=image_tensor.size(),\n",
    "        align_corners=False\n",
    "    )\n",
    "\n",
    "    # Apply rotations using grid sampling\n",
    "    rotated_images = F.grid_sample(\n",
    "        image_tensor,\n",
    "        grids,\n",
    "        mode='bilinear',\n",
    "        padding_mode='zeros',\n",
    "        align_corners=False\n",
    "    )\n",
    "\n",
    "    return rotated_images, rotation_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "944c0bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusor_batch_rotated_t, rotation_matrices = random_rotate_3d_batch(diffusor_batch_t)\n",
    "diffusor_in_fov_rotated_t = vs.diffusor_in_fov(diffusor_batch_rotated_t, diffusor_origin_batch.cuda(), diffusor_end_batch.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222764f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9f49770",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_ = []\n",
    "VF_ = []\n",
    "\n",
    "for diff_in_fov in diffusor_in_fov_rotated_t:\n",
    "        \n",
    "        diff_in_fov = diff_in_fov.reshape(-1, 1)\n",
    "        \n",
    "        V_filtered = V_fov[diff_in_fov.squeeze() == 5]\n",
    "        F_filtered = diff_in_fov[diff_in_fov.squeeze() == 5]\n",
    "        V_.append(V_filtered)\n",
    "        VF_.append(F_filtered)\n",
    "\n",
    "V_rotated = pad_sequence(V_, batch_first=True, padding_value=0.0) \n",
    "VF_rotated = pad_sequence(VF_, batch_first=True, padding_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3fad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_v = V_rotated\n",
    "SN = 0\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(x=x_v[SN,:,0].detach().cpu().numpy(), y=x_v[SN,:,1].detach().cpu().numpy(), z=x_v[SN,:,2].detach().cpu().numpy(), mode='markers', marker=dict(\n",
    "        size=2,\n",
    "        color=x_v[SN,:,2].detach().cpu().numpy(),                # set color to an array/list of desired values\n",
    "        colorscale='jet',   # choose a colorscale\n",
    "        # opacity=0.5\n",
    "    ))])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a3925be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_batch_rotation(V, rotation_matrices):\n",
    "    \"\"\"\n",
    "    Applies a batch of rotation matrices to a batch of 3D points.\n",
    "\n",
    "    Args:\n",
    "        V (torch.Tensor): A tensor of shape (BS, N, 3) containing 3D points.\n",
    "        rotation_matrices (torch.Tensor): A tensor of shape (BS, 3, 3) containing rotation matrices.\n",
    "\n",
    "    Returns:\n",
    "        rotated_points (torch.Tensor): A tensor of shape (BS, N, 3) with rotated points.\n",
    "    \"\"\"\n",
    "    assert V.shape[-1] == 3, \"Points tensor must have the last dimension of size 3 (3D coordinates).\"\n",
    "    assert rotation_matrices.shape[-2:] == (3, 3), \"Rotation matrices must have shape (BS, 3, 3).\"\n",
    "    assert V.shape[0] == rotation_matrices.shape[0], \"Batch size of points and rotation matrices must match.\"\n",
    "\n",
    "    # Apply the rotation matrix to each batch element\n",
    "    rotated_points = torch.matmul(V, rotation_matrices)  # Transpose for proper multiplication but here we don't transpose because the V tensor is ordered XYZ while the rotation matrix is ordered ZYX\n",
    "    # rotated_points = torch.matmul(V, rotation_matrices.transpose(1, 2))  # Transpose for proper multiplication\n",
    "    return rotated_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b6d7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_rotated = apply_batch_rotation(P.float().cuda(), rotation_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(x=P_rotated[SN, :,2].detach().cpu().numpy(), y=P_rotated[SN, :,1].detach().cpu().numpy(), z=P_rotated[SN, :,0].detach().cpu().numpy(), mode='markers', marker=dict(\n",
    "        size=2,\n",
    "        color=P_rotated[SN, :,2].detach().cpu().numpy(),                # set color to an array/list of desired values\n",
    "        colorscale='jet',   # choose a colorscale\n",
    "        # opacity=0.5\n",
    "    ))])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed7984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
